# ğŸ¥ AI Medical Chatbot

A comprehensive RAG (Retrieval-Augmented Generation) system for medical information retrieval and question answering, built with FastAPI, Streamlit, and advanced ML components.

## ğŸ¯ Features

- **ğŸ“š Medical Knowledge Base**: 5,895 document chunks from medical literature
- **ğŸ¤– AI-Powered Responses**: Groq Llama-3.1-8b-instant for accurate medical Q&A
- **ğŸ“± Mobile-Friendly UI**: Responsive design that works on all devices
- **ğŸ“„ File Upload**: Support for PDF documents and medical images
- **ğŸ”¬ Enhanced Mode**: ML classification, clustering, and summarization
- **âš¡ Fast Performance**: Optimized for quick response times

## ğŸš€ Quick Start

### Prerequisites
- Python 3.8+
- Groq API key

### Installation

1. **Clone the repository**
```bash
git clone https://github.com/mumar318/AI_Medicalchatbot.git
cd AI_Medicalchatbot
```

2. **Install dependencies**
```bash
pip install -r requirements.txt
```

3. **Set up environment variables**
```bash
# Create .env file with your Groq API key
echo "GROQ_API_KEY=your_groq_api_key_here" > .env
```

4. **Run the complete setup**
```bash
python run_complete_pipeline.py
```

5. **Start the application**
```bash
# Terminal 1: Start backend API
cd backend
python -m uvicorn api:app --reload --port 8000

# Terminal 2: Start frontend UI
cd frontend
python -m streamlit run app.py --server.port=8501
```

6. **Access the application**
- Local: http://localhost:8501
- Network: http://your-ip:8501

## ğŸ“ Project Structure

```
AI_Medicalchatbot/
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ api.py              # FastAPI backend
â”‚   â”œâ”€â”€ simple_rag.py       # RAG implementation
â”‚   â”œâ”€â”€ enhanced_rag.py     # Enhanced RAG with ML
â”‚   â”œâ”€â”€ ml_components.py    # ML classification/clustering
â”‚   â”œâ”€â”€ evaluation.py       # System evaluation
â”‚   â”œâ”€â”€ ingest.py          # Data processing
â”‚   â””â”€â”€ run_setup.py       # Setup script
â”œâ”€â”€ frontend/
â”‚   â”œâ”€â”€ app.py             # Streamlit interface
â”‚   â””â”€â”€ .streamlit/        # Configuration
â”œâ”€â”€ chroma_db/             # Vector database
â”œâ”€â”€ data/                  # Medical dataset
â”œâ”€â”€ notebooks/             # Data processing
â”œâ”€â”€ .env                   # API keys (create this)
â”œâ”€â”€ README.md              # This file
â”œâ”€â”€ requirements.txt       # Dependencies
â”œâ”€â”€ run_complete_pipeline.py # Complete setup
â”œâ”€â”€ run_streamlit.py       # UI launcher
â”œâ”€â”€ SYSTEM_STATUS.md       # System status
â””â”€â”€ PART_4_REPORT_REFLECTION.md # Development report
```

## ğŸ¯ Usage

### Basic Usage
1. Open http://localhost:8501 in your browser
2. Type medical questions like "What is diabetes?"
3. Click "ğŸš€ Ask" to get AI-powered responses
4. Use "â•" button to upload PDF documents or images

### Enhanced Mode
- Toggle "ğŸ”¬ Enhanced Mode" for ML features
- Get question classification and improved retrieval
- View confidence scores for AI responses

### Example Questions
- "What are the symptoms of diabetes?"
- "How is blood pressure measured?"
- "What causes heart disease?"
- "What are the side effects of antibiotics?"

## ğŸ”§ Technical Details

### Architecture
- **Backend**: FastAPI with RAG pipeline
- **Frontend**: Streamlit with responsive design
- **Database**: ChromaDB vector database
- **LLM**: Groq Llama-3.1-8b-instant
- **Embeddings**: sentence-transformers/all-MiniLM-L6-v2

### ML Components
1. **Question Classification**: Categorizes medical queries
2. **Document Clustering**: Groups similar content
3. **Summarization**: Generates context summaries

### Performance
- **Response Time**: < 3 seconds average
- **Knowledge Base**: 5,895 medical document chunks
- **Concurrent Users**: Supports multiple simultaneous users
- **Mobile Optimized**: Works on phones, tablets, desktops

## ğŸ“Š Assignment Components

This project fulfills all assignment requirements:

- âœ… **Part 1**: Data processing and embeddings (notebooks/data_processing.ipynb)
- âœ… **Part 2**: Complete RAG implementation (backend/simple_rag.py)
- âœ… **Part 3**: All ML components implemented (backend/ml_components.py)
- âœ… **Part 4**: Comprehensive report (PART_4_REPORT_REFLECTION.md)

## ğŸ› ï¸ Development

### Running in Development Mode
```bash
# Backend with auto-reload
cd backend
python -m uvicorn api:app --reload --port 8000

# Frontend with auto-reload
cd frontend
streamlit run app.py --server.port=8501
```

### Testing
The system includes comprehensive evaluation metrics and testing capabilities.

## ğŸ“ Documentation

- **System Status**: See SYSTEM_STATUS.md
- **Development Report**: See PART_4_REPORT_REFLECTION.md
- **Data Processing**: See notebooks/data_processing.ipynb

## âš ï¸ Important Notes

- **Educational Use Only**: Not for medical diagnosis or treatment
- **API Key Required**: Get your Groq API key from https://console.groq.com/
- **Data Privacy**: All processing is done locally
- **Medical Disclaimer**: Always consult healthcare professionals

## ğŸ¤ Contributing

1. Fork the repository
2. Create a feature branch
3. Make your changes
4. Test thoroughly
5. Submit a pull request

## ğŸ“„ License

This project is for educational purposes. Please ensure compliance with medical data regulations in your jurisdiction.

## ğŸ™ Acknowledgments

- Medical literature dataset for knowledge base
- Groq for fast LLM inference
- ChromaDB for vector storage
- Streamlit for rapid UI development

---

**ğŸŒ Live Demo**: http://localhost:8501 (when running locally)

**ğŸ“§ Contact**: For questions about this educational project

**â­ Star this repo** if you find it helpful for learning RAG systems!
